{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6D3rHhQqAum"
   },
   "source": [
    "# NETID: <fill in here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChDh8hwjtMVh"
   },
   "source": [
    "# Assessing Model Accuracy\n",
    "In this lesson, we look over different ways to evaluate whether machine learning models you have created successfully accomplish their intended objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H870tIe_tMWj",
    "outputId": "3d74f19c-1b3d-48bd-b3da-2d736a5979c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noncategorical Features:  ['Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formatted Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Precip Type</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Apparent Temperature (C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Wind Bearing (degrees)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Loud Cover</th>\n",
       "      <th>Pressure (millibars)</th>\n",
       "      <th>Daily Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 00:00:00.000 +0200</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.472222</td>\n",
       "      <td>7.388889</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1197</td>\n",
       "      <td>251.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.13</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 01:00:00.000 +0200</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.355556</td>\n",
       "      <td>7.227778</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.2646</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.63</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 02:00:00.000 +0200</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.9284</td>\n",
       "      <td>204.0</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 03:00:00.000 +0200</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.288889</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.1036</td>\n",
       "      <td>269.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.41</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 04:00:00.000 +0200</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>6.977778</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Formatted Date        Summary Precip Type  Temperature (C)  \\\n",
       "0  2006-04-01 00:00:00.000 +0200  Partly Cloudy        rain         9.472222   \n",
       "1  2006-04-01 01:00:00.000 +0200  Partly Cloudy        rain         9.355556   \n",
       "2  2006-04-01 02:00:00.000 +0200  Mostly Cloudy        rain         9.377778   \n",
       "3  2006-04-01 03:00:00.000 +0200  Partly Cloudy        rain         8.288889   \n",
       "4  2006-04-01 04:00:00.000 +0200  Mostly Cloudy        rain         8.755556   \n",
       "\n",
       "   Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n",
       "0                  7.388889      0.89            14.1197   \n",
       "1                  7.227778      0.86            14.2646   \n",
       "2                  9.377778      0.89             3.9284   \n",
       "3                  5.944444      0.83            14.1036   \n",
       "4                  6.977778      0.83            11.0446   \n",
       "\n",
       "   Wind Bearing (degrees)  Visibility (km)  Loud Cover  Pressure (millibars)  \\\n",
       "0                   251.0          15.8263         0.0               1015.13   \n",
       "1                   259.0          15.8263         0.0               1015.63   \n",
       "2                   204.0          14.9569         0.0               1015.94   \n",
       "3                   269.0          15.8263         0.0               1016.41   \n",
       "4                   259.0          15.8263         0.0               1016.51   \n",
       "\n",
       "                       Daily Summary  \n",
       "0  Partly cloudy throughout the day.  \n",
       "1  Partly cloudy throughout the day.  \n",
       "2  Partly cloudy throughout the day.  \n",
       "3  Partly cloudy throughout the day.  \n",
       "4  Partly cloudy throughout the day.  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "weather = pd.read_csv('lecture5dataA.csv').dropna()\n",
    "noncategorical = [weather.columns[i] for i in range (3,11) if i != 9]\n",
    "print (\"Noncategorical Features: \", noncategorical)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWpTFF27tMXD"
   },
   "source": [
    "## Loss Functions and Accuracy\n",
    "\n",
    "In evaluating your models, it's important to remember that different models must be evaluated with the appropriate metric. Classification accuracy is not, for example, the same thing as the mean-squared error used in regression problems. Furthermore, a high score in either of those metrics does not prove a model is \"good\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvLepXLMqAut"
   },
   "source": [
    "## <span style=\"color:green\"><em>Problem 1</em></span>\n",
    "Edit the lines marked with TODO's below to do the following:\n",
    "1. Create two columns to `temperatures` to store Temperature and Apparent Temperature in Rankines. Rankines is a  weird unit of temperature. Temperature in Rankines is 9/5 * (temperature in Celcius) + 491.67.\n",
    "2. Train and predict two models: one for celcius and one for rankines\n",
    "3. Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uJrP_FSTqAuu"
   },
   "outputs": [],
   "source": [
    "temperatures = weather.loc[:,[\"Temperature (C)\", \"Apparent Temperature (C)\"]]\n",
    "temperatures[\"Temperature (R)\"] = 0 #TODO: replace the 0 (hint: you don't need a loop)\n",
    "temperatures[\"Apparent Temperature (R)\"] = 0 #TODO: replace the 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtyH-s_FqAuw"
   },
   "outputs": [],
   "source": [
    "celcius_model = LinearRegression()\n",
    "# TODO split data. goal is temperature in celcius, feature is apparent temperature in celcius.\n",
    "# Make sure that the names of your data for the two models are different! Otherwise, one will overwrite the other\n",
    "# Then, fit the model.\n",
    "\n",
    "\n",
    "x_tr_C, x_te_C, y_tr_C, y_te_C = # Fill in here\n",
    "\n",
    "\n",
    "rankines_model = LinearRegression()\n",
    "# TODO same as above, but for rankines\n",
    "\n",
    "\n",
    "x_tr_R, x_te_R, y_tr_R, y_te_R = # Fill in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGyhDcXBqAuy"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# TODO store the predictions for the test sets\n",
    "celcius_predictions = \"Fill in here\"\n",
    "rankines_predictions = \"Fill in here\"\n",
    "\n",
    "# TODO find mean squared error of each model's predictions\n",
    "celcius_MSE = mean_squared_error(\"Fill in here\", \"Fill in here\") # TODO\n",
    "rankines_MSE = mean_squared_error(\"Fill in here\", \"Fill in here\") # TODO\n",
    "\n",
    "print(\"celcius MSE:\", celcius_MSE)\n",
    "print(\"rankines MSE:\", rankines_MSE)\n",
    "print(\"\\n(if the MSE for rankines is 0, you missed something two cells above)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mlIL6hKoqAuz"
   },
   "source": [
    "#### The MSE's of the two models are significantly different -- one is more than triple the other. To inspect this difference, let's plot the predictions of the two models and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aO0zdvI1qAu0"
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(x_te_C, y_te_C)\n",
    "plt.plot(x_te_C, celcius_predictions, 'k', linewidth=4)\n",
    "plt.legend([\"Predictions\",\"Actual Values\"])\n",
    "plt.title('Celcius Linear Regression')\n",
    "plt.xlabel('Apparent Temperature (C)')\n",
    "plt.ylabel('Temperature (C)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(x_te_R, y_te_R)\n",
    "plt.plot(x_te_R, rankines_predictions, 'k', linewidth=4)\n",
    "plt.legend([\"Predictions\",\"Actual Values\"])\n",
    "plt.title('Rankines Linear Regression')\n",
    "plt.xlabel('Apparent Temperature (R)')\n",
    "plt.ylabel('Temperature (R)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akGRKGNsqAu2"
   },
   "source": [
    "#### The plots look the same! The only significant difference is the scale of the axes. That's why the MSE for Rankines is bigger: Rankines are generally greater than Celcius, and so their error is naturally bigger. To take care of this, we use a _baseline_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JcSBtmN3qAu2"
   },
   "source": [
    "### <span style=\"color:green\"><em>end of Problem 1</em></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRppePJSqAu3"
   },
   "source": [
    "## <span style=\"color:green\"><em>Problem 2</em></span>\n",
    "Follow the TODOs to calculate normalized scores for your Celcius and Rankines predictions. Then, calculate score = 1 - model_MSE / baseline_MSE. Ask TAs for help!\n",
    "You should use the same train/test split as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xIfk86AqAu3"
   },
   "outputs": [],
   "source": [
    "# TODO define baseline predictions for Celcius as an array for which each entry is `mean(test goal Celcius)`\n",
    "\n",
    "test_goal_mean_C = 0 # TODO\n",
    "baseline_C = np.full((len(celcius_predictions),), test_goal_mean_C)\n",
    "baseline_C_MSE = mean_squared_error(\"Fill in here\", \"Fill in here\")\n",
    "\n",
    "score_C = 0 # TODO set score_C equal to 1 - (celcius model) / (celcius baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EAL5ZmtqAu5"
   },
   "outputs": [],
   "source": [
    "# TODO now, do the same thing for Rankines to calculate score_K\n",
    "score_R = 0 # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOXPrezmqAu7"
   },
   "outputs": [],
   "source": [
    "print(\"sklearn's score for Celcius:\", celcius_model.score(\"TODO: Fill in here\",\"TODO: Fill in here\"))\n",
    "print(\"your calculated score:\", score_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEaLf1qqqAu-"
   },
   "outputs": [],
   "source": [
    "print(\"sklearn's score for Rankines:\", rankines_model.score(\"TODO: Fill in here\",\"TODO: Fill in here\"))\n",
    "print(\"your calculated score:\", score_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILj07BjGqAu_"
   },
   "source": [
    "### <span style=\"color:green\"><em>end of Problem 2</em></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygBr-b6otMVk"
   },
   "source": [
    "## Bias and Variance\n",
    "\n",
    "To understand one of the most important concepts in machine learning evaluation, the bias-variance tradeoff, we must first establish what each term means. Simply put, *bias* is the tendency of to systematically over or under-estimate something. For example, if a seesaw has starts off at an incline, then we can say that it is already biased to one side regardless of the weight of the people using it. On the other hand, *variance* measures how far some metric is from a mean value. High variance corresponds to more spread out observations while low variance corresponds to datapoints that're clumped closer together. \n",
    "\n",
    "How do these terms work in machine learning models? One way to think about a model that is highly biased is to consider the worst case- where the model fails to learn anything at all. Then, the model is held to its pre-training parameters, and thus biased towards these results. In the case of variance, the opposite is true. Consider a model whose parameters yield a fairly accurate average result. If it exhibits high variance, then its predictions will vary more from that average result, meaning it is more sensitive to any noise in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adVUPbRNtMVn"
   },
   "source": [
    "## Bias-Variance Tradeoff\n",
    "\n",
    "In the above example, we see the 'bias-variance tradeoff'. Simply put, the bias and variance of a model's predictions must be balanced as much as possible in order to find the best machine learning model for any task. As you may have guessed, high bias inherently means having low variance while high variance means having low bias- hence, the tradeoff. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFQc7_TxtMVq"
   },
   "source": [
    "## Overfitting and Underfitting\n",
    "\n",
    "Having a high bias means your model did not learn as much as it could have (*underfitting*), while having a high variance means the model was responsive to training data to the point that it does not generalize well (*overfitting*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F12pAtz0qAvB",
    "outputId": "138c9fc5-7e39-410e-c55d-b16a60349419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lannister,\n",
      "None,\n",
      "Targaryen,\n",
      "Greyjoy,\n",
      "Night's Watch,\n",
      "Arryn,\n",
      "Stark,\n",
      "Tyrell,\n",
      "Baratheon,\n",
      "Martell,\n",
      "Wildling,\n",
      "Tully\n"
     ]
    }
   ],
   "source": [
    "deaths = pd.read_csv('lecture5dataB.csv')\n",
    "deaths['Book of Death'].fillna(0,inplace=True)\n",
    "deaths['Death Year'].fillna(deaths['Death Year'].mean(),inplace=True)\n",
    "deaths.dropna(subset=['Book Intro Chapter'],inplace=True)\n",
    "deaths['Death Chapter'].fillna(deaths['Death Chapter'].mean(),inplace=True)\n",
    "deaths[\"Allegiances\"] = deaths[\"Allegiances\"].str.replace(pat=r'House (?P<one>.*)', repl=lambda m: m.group('one'))\n",
    "\n",
    "print(\",\\n\".join(deaths[\"Allegiances\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9b0HejanqAvE",
    "outputId": "1cd4997c-c154-43b1-c5fd-d52f4beb2f24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Allegiances</th>\n",
       "      <th>Death Year</th>\n",
       "      <th>Book of Death</th>\n",
       "      <th>Death Chapter</th>\n",
       "      <th>Book Intro Chapter</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Nobility</th>\n",
       "      <th>GoT</th>\n",
       "      <th>CoK</th>\n",
       "      <th>SoS</th>\n",
       "      <th>FfC</th>\n",
       "      <th>DwD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Addam Marbrand</td>\n",
       "      <td>Lannister</td>\n",
       "      <td>299.157377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.25</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aegon Frey (Jinglebell)</td>\n",
       "      <td>None</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aegon Targaryen</td>\n",
       "      <td>Targaryen</td>\n",
       "      <td>299.157377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adrack Humble</td>\n",
       "      <td>Greyjoy</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aemon Targaryen (son of Maekar I)</td>\n",
       "      <td>Night's Watch</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name    Allegiances  Death Year  \\\n",
       "0                     Addam Marbrand      Lannister  299.157377   \n",
       "1            Aegon Frey (Jinglebell)           None  299.000000   \n",
       "2                    Aegon Targaryen      Targaryen  299.157377   \n",
       "3                      Adrack Humble        Greyjoy  300.000000   \n",
       "6  Aemon Targaryen (son of Maekar I)  Night's Watch  300.000000   \n",
       "\n",
       "   Book of Death  Death Chapter  Book Intro Chapter  Gender  Nobility  GoT  \\\n",
       "0            0.0          40.25                56.0       1         1    1   \n",
       "1            3.0          51.00                49.0       1         1    0   \n",
       "2            0.0          40.25                 5.0       1         1    0   \n",
       "3            5.0          20.00                20.0       1         1    0   \n",
       "6            4.0          35.00                21.0       1         1    1   \n",
       "\n",
       "   CoK  SoS  FfC  DwD  \n",
       "0    1    1    1    0  \n",
       "1    0    1    0    0  \n",
       "2    0    0    0    1  \n",
       "3    0    0    0    1  \n",
       "6    0    1    1    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAXNzorAqAvG",
    "outputId": "af458228-fcfa-457f-a7be-e8df239e2738",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f39e7125055d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_tr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = deaths[['Death Year','Book Intro Chapter','Book of Death','Death Chapter']]\n",
    "Y = deaths['Allegiances']\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, Y, test_size = 0.2, random_state=42)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "max_depths = list(range(10,100))\n",
    "for i in max_depths:\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "\n",
    "    model.fit(x_tr, y_tr)\n",
    "    \n",
    "    train_scores.append(model.score(x_tr, y_tr))\n",
    "    test_scores.append(model.score(x_te, y_te))\n",
    "    \n",
    "plt.subplots(figsize=(15,5))\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.subplot(131)\n",
    "plt.plot(max_depths, train_scores)\n",
    "plt.title('Training Score: More complex is better')\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('Training Score')\n",
    "plt.subplot(132)\n",
    "plt.plot(max_depths, test_scores)\n",
    "plt.title(\"Testing Score: There's a sweetspot\")\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('Testing Score')\n",
    "plt.subplot(133)\n",
    "plt.plot(max_depths, np.subtract(train_scores,test_scores))\n",
    "plt.title(\"Generalization Error\")\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('(Training Score) - (Testing Score)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WlCOWCXqAvH"
   },
   "source": [
    "## <span style=\"color:green\"><em>Problem 3 (Optional)</em></span>\n",
    "### NOTE: there's a required Problem 4 at the bottom of the notebook. Don't skip it!\n",
    "### Part a\n",
    "Modify the loop above to programmatically find the best `max_depth` for a Decision Tree. Print out the training and testing score of just a model that uses that `max_depth`.\n",
    "You could also try using sklearn's `GridSearchCV` instead, which we will cover in a later lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cteIx6-qAvI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnYyymAOqAvK"
   },
   "source": [
    "### Part b\n",
    "Now, imagine if you get a `Lannister`'s allegiance wrong, there is a much harsher consequence. To be specific, for any Lannister, the penalty of not predicting that they're a Lannister is 5x the normal penalty. Adjust your scoring mechanism using this new metric (still produce a score normalized by baseline). If you used GridSearchCV above, then see if you can use GridSearchCV's `scoring` parameter.\n",
    "Note: we're dealing with classification here, not regression, so you'll need to use a classification loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tb9wc49vqAvK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjjL2kN3qAvM"
   },
   "source": [
    "### Part c\n",
    "Now, imagine that you care twice as much about people whose Death Year is greater than or equal to `300`. Adjust your scoring mechanism using this new metric (still produce a score normalized by baseline). sklearn's typical scoring parameter doesn't allow for this, so you can't use GridSearchCV (as far as I know -- I could be wrong)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ali_1-tqAvM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lNmvNm_qAvO"
   },
   "source": [
    "### <span style=\"color:green\"><em>end of Problem 3</em></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xM4wvFwQtMWh"
   },
   "source": [
    "## Feature-Subset Selection Techniques \n",
    "\n",
    "\n",
    "A dataset will usually have many features, many of which will not be useful at all. The key is to determine which are helpful in improving your model.\n",
    "\n",
    "Use the following block to help decide if a particular feature subset selection is helpful for a linear model built on a dataset of a Hungarian city called Szeged. Feel free to modify it to suit your needs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfMYgEertMWs",
    "outputId": "7d0c6889-6e47-4744-f544-0f17caccf770"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Apparent Temperature (C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Wind Bearing (degrees)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Pressure (millibars)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95936.000000</td>\n",
       "      <td>95936.000000</td>\n",
       "      <td>95936.000000</td>\n",
       "      <td>95936.000000</td>\n",
       "      <td>95936.000000</td>\n",
       "      <td>95936.000000</td>\n",
       "      <td>95936.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.940976</td>\n",
       "      <td>10.862531</td>\n",
       "      <td>0.734841</td>\n",
       "      <td>10.804936</td>\n",
       "      <td>187.518773</td>\n",
       "      <td>10.362402</td>\n",
       "      <td>1003.150038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.570671</td>\n",
       "      <td>10.717812</td>\n",
       "      <td>0.195724</td>\n",
       "      <td>6.920727</td>\n",
       "      <td>107.385351</td>\n",
       "      <td>4.173780</td>\n",
       "      <td>117.276976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-21.822222</td>\n",
       "      <td>-27.716667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.604167</td>\n",
       "      <td>2.276389</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5.796000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>8.372000</td>\n",
       "      <td>1011.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.033333</td>\n",
       "      <td>12.033333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>9.933700</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>10.046400</td>\n",
       "      <td>1016.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.844444</td>\n",
       "      <td>18.844444</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>14.135800</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>14.812000</td>\n",
       "      <td>1021.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.905556</td>\n",
       "      <td>39.344444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.852600</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>1046.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature (C)  Apparent Temperature (C)      Humidity  \\\n",
       "count     95936.000000              95936.000000  95936.000000   \n",
       "mean         11.940976                 10.862531      0.734841   \n",
       "std           9.570671                 10.717812      0.195724   \n",
       "min         -21.822222                -27.716667      0.000000   \n",
       "25%           4.604167                  2.276389      0.600000   \n",
       "50%          12.033333                 12.033333      0.780000   \n",
       "75%          18.844444                 18.844444      0.890000   \n",
       "max          39.905556                 39.344444      1.000000   \n",
       "\n",
       "       Wind Speed (km/h)  Wind Bearing (degrees)  Visibility (km)  \\\n",
       "count       95936.000000            95936.000000     95936.000000   \n",
       "mean           10.804936              187.518773        10.362402   \n",
       "std             6.920727              107.385351         4.173780   \n",
       "min             0.000000                0.000000         0.000000   \n",
       "25%             5.796000              116.000000         8.372000   \n",
       "50%             9.933700              180.000000        10.046400   \n",
       "75%            14.135800              290.000000        14.812000   \n",
       "max            63.852600              359.000000        16.100000   \n",
       "\n",
       "       Pressure (millibars)  \n",
       "count          95936.000000  \n",
       "mean            1003.150038  \n",
       "std              117.276976  \n",
       "min                0.000000  \n",
       "25%             1011.890000  \n",
       "50%             1016.420000  \n",
       "75%             1021.050000  \n",
       "max             1046.380000  "
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[noncategorical].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGOJPEm7tMW4"
   },
   "source": [
    "## <span style=\"color:green\"><em>Problem 4</em></span>\n",
    "\n",
    "Using what you have learned, create a correlation matrix of the data. Use it to decide the three best features to use in predicting Humidity and store those in a list named `three_correlated_features`. Then store the two best features to in a list named `two_correlated_features`. Compare the result of using `three_correlated_features` vs `two_correlated_features` to train a Linear Regression. (When we say compare the results, we mean compare print out the scores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwN1_pEUtMXD"
   },
   "source": [
    "Your results should show you an important lesson about feature selection- you don't always need to have all features to show almost the same results, and selecting a feature subset of lesser size may be more resource-efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csjZXn9fqAvX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fAVKAfEqAvf"
   },
   "source": [
    "### <span style=\"color:green\"><em> end of Problem 4 </em></span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture 5 - Assessing Model Accuracy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notebookId": "^E||G=G=bpDp\\gp"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
