{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"notebookId":"PAG=GBo}Q}it}","colab":{"name":"Lecture6-Demo.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"scrolled":true,"id":"EP0BnPZ7VBQc","outputId":"7947d812-2b05-4867-8ca5-410fe1cd6d5e"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","df = pd.read_csv('lecture6data.csv')\n","df=df.drop('Unnamed: 32',axis=1)\n","df=df.drop('id',axis=1)\n","df.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>symmetry_mean</th>\n","      <th>...</th>\n","      <th>radius_worst</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>M</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>...</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>...</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>...</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>...</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>...</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 31 columns</p>\n","</div>"],"text/plain":["  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n","0         M        17.99         10.38          122.80     1001.0   \n","1         M        20.57         17.77          132.90     1326.0   \n","2         M        19.69         21.25          130.00     1203.0   \n","3         M        11.42         20.38           77.58      386.1   \n","4         M        20.29         14.34          135.10     1297.0   \n","\n","   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n","0          0.11840           0.27760          0.3001              0.14710   \n","1          0.08474           0.07864          0.0869              0.07017   \n","2          0.10960           0.15990          0.1974              0.12790   \n","3          0.14250           0.28390          0.2414              0.10520   \n","4          0.10030           0.13280          0.1980              0.10430   \n","\n","   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n","0         0.2419  ...         25.38          17.33           184.60   \n","1         0.1812  ...         24.99          23.41           158.80   \n","2         0.2069  ...         23.57          25.53           152.50   \n","3         0.2597  ...         14.91          26.50            98.87   \n","4         0.1809  ...         22.54          16.67           152.20   \n","\n","   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n","0      2019.0            0.1622             0.6656           0.7119   \n","1      1956.0            0.1238             0.1866           0.2416   \n","2      1709.0            0.1444             0.4245           0.4504   \n","3       567.7            0.2098             0.8663           0.6869   \n","4      1575.0            0.1374             0.2050           0.4000   \n","\n","   concave points_worst  symmetry_worst  fractal_dimension_worst  \n","0                0.2654          0.4601                  0.11890  \n","1                0.1860          0.2750                  0.08902  \n","2                0.2430          0.3613                  0.08758  \n","3                0.2575          0.6638                  0.17300  \n","4                0.1625          0.2364                  0.07678  \n","\n","[5 rows x 31 columns]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"kf2MgkdDVBQe"},"source":["## <span style=\"color:purple\">_Problem 1_</span>\n","\n","Build a kNN model predicting whether an observation is benign or malignant. You should split the dataset into a training set and a test set as covered previously in the course, fit the model on the observations in the training set, and predict the target variable for the test set.\n","\n","There are a couple of things to note for this problem. First, you are free to choose whichever features you want to predict the target feature, but you should not use id or the target variable itself. Second, you can optionally choose the k parameter for the kNN model (the default value is 5).\n","\n","Save your predictions in a variable named \"predictions\".\n","\n","**Please do not change the variable names already provided as they are used later in the demo**"]},{"cell_type":"code","metadata":{"id":"PABTdW4IVBQf"},"source":["X=df.drop('diagnosis',axis=1) \n","y=df['diagnosis'] \n","\n","# TODO train test split your data with 20% being used for testing\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n","\n","# This is the function we use to create the kNN model (default k=5)\n","model = KNeighborsClassifier()\n","\n","# TODO fit the model using the train data\n","model.fit(x_train, y_train) \n","\n","# TODO store the predictions for the test sets\n","predictions = model.predict(x_test) \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DHh3ZsGVBQg"},"source":["# TODO find the accuracy score of your predictions\n","from sklearn.metrics import accuracy_score\n","print(\"sklearn's accuracy score for diagnosis:\", accuracy_score(\"FILL IN HERE\", \"FILL IN HERE\")) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-BP31ssCVBQh"},"source":["### <span style=\"color:purple\"> _end of Problem 1_</span>"]},{"cell_type":"markdown","metadata":{"id":"qw2dX_IbVBQh"},"source":["## Measuring Accuracy\n","\n","Measuring the accuracy of classifiers is more intuitive than calculating the accuracy of a linear regression model. When we predict categorical values, our accuracy score is simply the proportion of values that we computed correctly. For example, if we have a test set of size 100 and we predict 93 of the observations correctly, we have an accuracy score of 93 percent."]},{"cell_type":"code","metadata":{"id":"6Vsx2irNVBQi","outputId":"8356771a-f54c-47e7-88e0-c202bb1d3299"},"source":["# Compute the accuracy score of the model created above\n","accuracy = accuracy_score(y_test, predictions)\n","print('accuracy:',accuracy)\n","\n","# Compute the accuracy of predicting all diagnoses are benign\n","y_train.describe()\n","y_test.describe()\n","base_array = np.full(114, 'B')\n","\n","baseline = accuracy_score(y_test, base_array)\n","print('baseline:',baseline)\n","\n","# Compute the percent improvement from the baseline\n","improvement = (accuracy - baseline) / baseline\n","print('improvment',improvement)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy: 0.956140350877193\n","baseline: 0.6228070175438597\n","improvment 0.5352112676056336\n"]}]},{"cell_type":"markdown","metadata":{"id":"HYFFfHPLVBQj"},"source":["The above improvement shows just how beneficial the kNN model can be. It also shows us that we have chosen an appropriate value for k because there is an improvement over the baseline assumption (average category of values).\n","\n","## Fit/Overfitting\n","\n","Below are accuracy scores of the same kNN model, but with the value of k changing. Note how the accuracy changes as k increases. As mentioned during the lecture, a high value of k can improve the accuracy of the model, but too high a value of k will essentially be the average of all of the data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"mDaqx94tVBQj","executionInfo":{"status":"error","timestamp":1635297715551,"user_tz":240,"elapsed":297,"user":{"displayName":"Samantha Cobado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11381809090961349654"}},"outputId":"d7ded433-f48b-4be1-d013-da66b8b6de4f"},"source":["# Model when k=1\n","model1 = KNeighborsClassifier(1)\n","model1.fit(x_train, y_train)\n","predictions1 = model1.predict(x_test)\n","\n","# Model when k=10\n","model10 = KNeighborsClassifier(10)\n","model10.fit(x_train, y_train)\n","predictions10 = model10.predict(x_test)\n","\n","# Model when k=100\n","model100 = KNeighborsClassifier(100)\n","model100.fit(x_train, y_train)\n","predictions100 = model100.predict(x_test)\n","\n","print(\"accuracy score when k=1:\", accuracy_score(y_test, predictions1))\n","print(\"accuracy score when k=10:\", accuracy_score(y_test, predictions10))\n","print(\"accuracy score when k=100:\", accuracy_score(y_test, predictions100))\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-773dfe11c5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model when k=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"idMbPYX2VBQl"},"source":["## Confusion Matrix\n","\n","**Reminder**: The confusion matrix is depicted below\n","\n","<style type=\"text/css\">\n",".tg  {border-collapse:collapse;border-spacing:0;}\n",".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}\n",".tg .tg-ik58{background-color:#ffcb2f;border-color:inherit;text-align:left;vertical-align:top}\n",".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n","</style>\n","<table class=\"tg\">\n","  <tr>\n","    <td class=\"tg-ik58\"></td>\n","    <td class=\"tg-ik58\">Positive'<br>(Predicted)</td>\n","    <td class=\"tg-ik58\">Negative'<br>(Predicted)</td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\">Positive<br>(Actual)</td>\n","    <td class=\"tg-0pky\">True Positive</td>\n","    <td class=\"tg-0pky\">False Negative</td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\">Negative<br>(Actual)</td>\n","    <td class=\"tg-0pky\">False Positive</td>\n","    <td class=\"tg-0pky\">True Negative</td>\n","  </tr>\n","</table>\n","\n","Here are the equations specified in the lecture for your convenience with the next problem.\n","\n","**Sensitivity** = True Positive /(True Positive + False Negative)\n","\n","**Specificity** = True Negative /(True Negative + False Positive)\n","\n","**Accuracy** = (True Positive + True Negative) / Total\n","\n","**Error** = (False Positive + False Negative) / Total\n","\n","**Precision** = True Positive / (True Positive + False Positive) "]},{"cell_type":"code","metadata":{"id":"dDZr1xIndrZc"},"source":[""],"execution_count":null,"outputs":[]}]}